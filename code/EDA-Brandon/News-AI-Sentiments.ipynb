{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import quick EDA Module\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initial Auto-Explore\n",
    "# folder_name = 'News_AI_Sentiments'\n",
    "# # Explore all CSV data in folder, plot distributions of values and dates\n",
    "# quick_explore(folder = folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explicit function to load data with Auto-Preprocessing for early EDA\n",
    "# folder_name = 'Sample_dataset'\n",
    "# directory = '../data/News_AI_Sentiments/'\n",
    "# for filename in os.listdir(directory):\n",
    "#     \n",
    "#     filepath = os.path.join(directory, filename)\n",
    "#     \n",
    "#     if filename.endswith('.csv'):\n",
    "#         raw_df = pd.read_csv(filepath, infer_datetime_format = True)\n",
    "#         neg_index = 4\n",
    "# \n",
    "#     elif filename.endswith('.xlsx'):\n",
    "#         raw_df = pd.read_excel(filepath, infer_datetime_format = True)\n",
    "#         neg_index = 5\n",
    "#         \n",
    "#     else:\n",
    "#         continue\n",
    "#         \n",
    "#     print()\n",
    "#     print('--------------'*8)\n",
    "#     print('--------------'*8)\n",
    "#     print(filename[:-neg_index].upper())\n",
    "#     print()\n",
    "#     \n",
    "#     df, redund_dict = preprocess_data(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any item in ONE is also in TWO\n",
    "def FIND_OVERLAP(one, two):\n",
    "    category_1 = one\n",
    "    category_2 = two\n",
    "    overlap = [source for source in category_1 if source in category_2]\n",
    "    print(f'{len(overlap)} sources found in overlap')\n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap = [source for source in global_news if source in financial_news]\n",
    "# len(overlap)\n",
    "# \n",
    "# global_not_financial = [source for source in global_news if source not in financial_news]\n",
    "# len(global_not_financial)\n",
    "# \n",
    "# financial_not_global = [source for source in financial_news if source not in global_news]\n",
    "# len(financial_not_global)\n",
    "# \n",
    "# financial_not_finoil = [source for source in financial_news if source not in financial_oil]\n",
    "# len(financial_not_finoil)\n",
    "# \n",
    "# finoil_not_financial = [source for source in financial_oil if source not in financial_news]\n",
    "# len(finoil_not_financial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  From https://mediabiasfactcheck.com/fake-news/\n",
    "#  https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "# \n",
    "# questionable_media = pd.DataFrame(questionable_sources, columns=['questionable_sources'])\n",
    "# for index, media in enumerate(questionable_media.questionable_sources):\n",
    "#     questionable_media.questionable_sources[index] = re.sub(r'\\([^)]*\\)', '', media).upper().strip()\n",
    "# questionable_media.to_csv(r'./questionable_news_sources.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Global News Sources\n",
    "# media_df = pd.DataFrame(global_news, columns=['news'])\n",
    "# media_df['financial_news'] = 0\n",
    "# media_df\n",
    "# \n",
    "# # Global-FINANCIAL News Sources\n",
    "# media1_df = pd.DataFrame(financial_news, columns=['news'])\n",
    "# media1_df['financial_news'] = 1\n",
    "# media1_df\n",
    "# \n",
    "# # Merge the two labelled groups of news-media sources\n",
    "# media_df = pd.concat([media_df,media1_df], ignore_index=True, axis=0)\n",
    "# media_df.sort_values(by='news', ignore_index = True)\n",
    "# #media_df.to_csv(r'./news_media.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media Bias Fact Check\n",
    "fact_reporting = {'Very High':5,\n",
    "                  'High':4,\n",
    "                  'Mostly Factual':3,\n",
    "                  'Mixed':2,\n",
    "                  'Lov':1,\n",
    "                  'Very Low':0}\n",
    "\n",
    "bias = {'Party2': 2, # right\n",
    "        'Party2 Center': 1,\n",
    "        'Least Biased': 0,\n",
    "        'Party1 Center':-1,\n",
    "        'Party1': -2 } # left\n",
    "\n",
    "# Press Freedom Index, World Press Freedom Rank, for countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From https://mediabiasfactcheck.com/fake-news/\n",
    "# # https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "# left_df = pd.DataFrame(left_biased, columns=['news'])\n",
    "# for index, media in enumerate(left_df.news):\n",
    "#     left_df.news[index] = re.sub(r'\\([^)]*\\)', '', media).upper().strip()\n",
    "# left_df['bias'] = -2\n",
    "# left_df.to_csv(r'./left_bias.csv', index = False)\n",
    "# left_df\n",
    "# \n",
    "# # From https://mediabiasfactcheck.com/fake-news/\n",
    "# # https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "# left_center_df = pd.DataFrame(left_center_bias, columns=['news'])\n",
    "# for index, media in enumerate(left_center_df.news):\n",
    "#     left_center_df.news[index] = re.sub(r'\\([^)]*\\)', '', media).upper().strip()\n",
    "# left_center_df['bias'] = -1\n",
    "# left_center_df.to_csv(r'./left_center_bias.csv', index = False)\n",
    "# left_center_df\n",
    "# \n",
    "# # From https://mediabiasfactcheck.com/fake-news/\n",
    "# # https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "# right_center_df = pd.DataFrame(right_center_bias, columns=['news'])\n",
    "# for index, media in enumerate(right_center_df.news):\n",
    "#     right_center_df.news[index] = re.sub(r'\\([^)]*\\)', '', media).upper().strip()\n",
    "# right_center_df['bias'] = 1\n",
    "# right_center_df.to_csv(r'./right_center_bias.csv', index = False)\n",
    "# right_center_df\n",
    "# \n",
    "# # From https://mediabiasfactcheck.com/fake-news/\n",
    "# # https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "# right_df = pd.DataFrame(right_biased, columns=['news'])\n",
    "# for index, media in enumerate(right_df.news):\n",
    "#     right_df.news[index] = re.sub(r'\\([^)]*\\)', '', media).upper().strip()\n",
    "# right_df['bias'] = 2\n",
    "# right_df.to_csv(r'./right_bias.csv', index = False)\n",
    "# right_df\n",
    "# \n",
    "# # From https://mediabiasfactcheck.com/fake-news/\n",
    "# # https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "# least_df = pd.DataFrame(least_biased, columns=['news'])\n",
    "# for index, media in enumerate(least_df.news):\n",
    "#     least_df.news[index] = re.sub(r'\\([^)]*\\)', '', media).upper().strip()\n",
    "# least_df['bias'] = 0\n",
    "# least_df.to_csv(r'./least_bias.csv', index = False)\n",
    "# least_df\n",
    "# \n",
    "# # Merge all of the bias ranked media sources together\n",
    "# bias_df = pd.concat([left_df, left_center_df, least_df, right_center_df, right_df],\n",
    "#                     ignore_index=True,\n",
    "#                     axis=0)\n",
    "# bias_df.sort_values(by='news',\n",
    "#                     ignore_index = True,\n",
    "#                     inplace = True)\n",
    "# #bias_df.to_csv(r'./bias.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>financial_news</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/7 WALL ST.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABA BANKING JOURNAL</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC NEWS</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALTERNATIVE ENERGY STOCKS</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>WUXI DAILY</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>YAHOO FINANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>YANGTSE EVENING POST</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>ZACKS INVESTMENT RESEARCH</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>ZHONGSHAN DAILY</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          news  financial_news  bias\n",
       "0                24/7 WALL ST.               1   0.0\n",
       "1          ABA BANKING JOURNAL               1   NaN\n",
       "2                          ABC               0   1.0\n",
       "3                     ABC NEWS               0  -1.0\n",
       "4    ALTERNATIVE ENERGY STOCKS               1   NaN\n",
       "..                         ...             ...   ...\n",
       "461                 WUXI DAILY               0   NaN\n",
       "462              YAHOO FINANCE               1   NaN\n",
       "463       YANGTSE EVENING POST               0   NaN\n",
       "464  ZACKS INVESTMENT RESEARCH               1   NaN\n",
       "465            ZHONGSHAN DAILY               0   NaN\n",
       "\n",
       "[466 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_news = pd.read_csv('./news_media.csv')\n",
    "global_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735   -1\n",
       "Name: bias, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_df.loc[bias_df['news'] == 'HOUSTON CHRONICLE', 'bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54   -1.0\n",
       "Name: bias, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = global_news.loc[global_news['news'] == 'CHRON', 'bias']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_news[global_news['news']=='CHRON'].index\n",
    "global_news.loc[global_news['news'] == 'CHRON', 'bias'] = bias_df.loc[bias_df['news'] == 'HOUSTON CHRONICLE', 'bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_news.loc[global_news['news'] == 'CHRON', 'bias'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = 'HOUSTON CHRONICLE' \n",
    "row = bias_df.loc[bias_df.isin([search]).any(axis=1)].index\n",
    "global_news.loc[global_news['news'] == 'CHRON', 'bias'] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54    735.0\n",
       "Name: bias, dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_news.loc[global_news['news'] == 'CHRON', 'bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010 WINS AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 NEWS KPNX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1440 NEWSLETTER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600 DAILY</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24/7 WALL ST.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>YOUR BLACK WORLD</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>YOUTH RADIO</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>Z MAGAZINE</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>ZDNET</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>ZEBRA FACT CHECK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news  bias\n",
       "0         1010 WINS AM     0\n",
       "1         12 NEWS KPNX     0\n",
       "2      1440 NEWSLETTER     0\n",
       "3           1600 DAILY    -1\n",
       "4        24/7 WALL ST.     0\n",
       "...                ...   ...\n",
       "1915  YOUR BLACK WORLD    -2\n",
       "1916       YOUTH RADIO    -1\n",
       "1917        Z MAGAZINE    -2\n",
       "1918             ZDNET     0\n",
       "1919  ZEBRA FACT CHECK     1\n",
       "\n",
       "[1920 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_df = pd.read_csv('./bias.csv')\n",
    "bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sources found in overlap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['news', 'bias']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIND_OVERLAP(global_news, bias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sources found in overlap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['news', 'bias']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIND_OVERLAP(bias_df, global_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_merge = global_news.merge(bias_df, how = 'left', on = 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news                0\n",
       "financial_news      0\n",
       "bias_x            312\n",
       "bias_y            353\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_merge.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>financial_news</th>\n",
       "      <th>bias_x</th>\n",
       "      <th>bias_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/7 WALL ST.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABA BANKING JOURNAL</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC NEWS</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALTERNATIVE ENERGY STOCKS</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>WUXI DAILY</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>YAHOO FINANCE</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>YANGTSE EVENING POST</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>ZACKS INVESTMENT RESEARCH</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>ZHONGSHAN DAILY</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          news  financial_news  bias_x  bias_y\n",
       "0                24/7 WALL ST.               1     0.0     0.0\n",
       "1          ABA BANKING JOURNAL               1     NaN     NaN\n",
       "2                          ABC               0     1.0     1.0\n",
       "3                     ABC NEWS               0    -1.0    -1.0\n",
       "4    ALTERNATIVE ENERGY STOCKS               1     NaN     NaN\n",
       "..                         ...             ...     ...     ...\n",
       "461                 WUXI DAILY               0     NaN     NaN\n",
       "462              YAHOO FINANCE               1     NaN     NaN\n",
       "463       YANGTSE EVENING POST               0     NaN     NaN\n",
       "464  ZACKS INVESTMENT RESEARCH               1     NaN     NaN\n",
       "465            ZHONGSHAN DAILY               0     NaN     NaN\n",
       "\n",
       "[466 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bias'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bias'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-999dd59401ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdummy_merge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdummy_merge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bias'"
     ]
    }
   ],
   "source": [
    "dummy_merge[dummy_merge['bias'].isna()].tail(60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df.news[1800:1860];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "non_matches = []\n",
    "non_match = 0\n",
    "multimatch = 0\n",
    "for gn in global_news.news:\n",
    "    count = 0\n",
    "    for bias in bias_df.news:\n",
    "        f = bias.find(gn)\n",
    "        if f != -1:\n",
    "            if count == 0:\n",
    "                first_match = gn\n",
    "                fm = bias\n",
    "                # Stop if an exact match is found on 1st try\n",
    "                if (gn == bias) | (gn[4:] == bias) | (gn == bias[4:]):\n",
    "                    count += 1\n",
    "                    break\n",
    "            elif count == 1:\n",
    "                # Perfect match found after one submatch found\n",
    "                if (gn == bias) | (gn[4:] == bias) | (gn == bias[4:]):\n",
    "                    first_match = gn\n",
    "                    fm = bias\n",
    "                    break\n",
    "                print()\n",
    "                print('MULTI-MATCH!')\n",
    "                print(f'Global: {first_match}, Bias: {fm}')\n",
    "                print(f'Global: {gn}, Bias: {bias}')\n",
    "            elif count > 1:\n",
    "                # Perfect match found after 2+ submatches were found\n",
    "                if (gn == bias) | (gn[4:] == bias) | (gn == bias[4:]):\n",
    "                    first_match = gn\n",
    "                    fm = bias\n",
    "                    count = 1\n",
    "                    break\n",
    "                print(f'Global: {gn}, Bias: {bias}')\n",
    "            count += 1\n",
    "        elif f == -1:\n",
    "            continue\n",
    "    if count == 0:\n",
    "        non_matches.append(gn)\n",
    "        non_match += 1\n",
    "    if count == 1:\n",
    "        try:\n",
    "            value = bias_df.loc[bias_df.news == first_match, 'bias'].values[0]\n",
    "            print()\n",
    "            print('ONE PERFECT MATCH!')\n",
    "            print(f'Global: {first_match}, Bias: {fm}')\n",
    "            matches.append((first_match, value))\n",
    "        except IndexError:\n",
    "            try:\n",
    "                value = bias_df.loc[bias_df.news == first_match[4:], 'bias'].values[0]\n",
    "                print()\n",
    "                print('ONE PERFECT MATCH!')\n",
    "                print(f'Global: {first_match}, Bias: {fm}')\n",
    "                matches.append((first_match, value))\n",
    "            except IndexError:\n",
    "                try:\n",
    "                    value = bias_df.loc[bias_df.news == ('THE '+first_match), 'bias'].values[0]\n",
    "                    print()\n",
    "                    print('ONE PERFECT MATCH!')\n",
    "                    print(f'Global: {first_match}, Bias: {fm}')\n",
    "                    matches.append((first_match, value))\n",
    "                except IndexError:\n",
    "                        print('!!!WARNING ------------------INEXACT MATCH FOUND----------------- WARNING!!!')\n",
    "                        print(f'Substring: {first_match}, Bias: {fm}')\n",
    "                        continue\n",
    "    elif count > 1:\n",
    "        print(f'Number of false matches: {count - 1}')\n",
    "        print()\n",
    "        multimatch += 1\n",
    "display(f'Single Matches: {len(matches)}')\n",
    "display(f'Multi Matches: {multimatch}')\n",
    "display(f'Non-Matches: {len(non_matches)}')\n",
    "display(f'Total news sources: {len(global_news)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches = []\n",
    "#non_matches = []\n",
    "non_matches_the = []\n",
    "non_match = 0\n",
    "multimatch = 0\n",
    "for gn in non_matches:\n",
    "    count = 0\n",
    "    for bias in bias_df.news:\n",
    "        if gn[:4] == 'THE ':\n",
    "            f = bias.find(gn[4:])\n",
    "        if f != -1:\n",
    "            if count == 0:\n",
    "                first_match = gn\n",
    "                fm = bias\n",
    "                #value = bias_df.loc[bias_df.news == first_match[4:], 'bias'].values[0]\n",
    "            elif count == 1:\n",
    "                print()\n",
    "                print('MULTI-MATCH!')\n",
    "                print(f'Global: {first_match}, Bias: {fm}')\n",
    "                print(f'Global: {gn}, Bias: {bias}')\n",
    "            elif count > 1:\n",
    "                print(f'Global: {gn}, Bias: {bias}')\n",
    "            count += 1\n",
    "        elif f == -1:\n",
    "            continue\n",
    "    if count == 0:\n",
    "        non_matches_the.append(gn)\n",
    "        non_match += 1\n",
    "    if count == 1:\n",
    "        print()\n",
    "        print('ONE MATCH!')\n",
    "        print(f'Global: {first_match}, Bias: {fm}')\n",
    "        if first_match[4:] == fm:\n",
    "            value = bias_df.loc[bias_df.news == first_match[4:], 'bias'].values[0]\n",
    "        matches.append((first_match, value))\n",
    "    elif count > 1:\n",
    "        print(f'Number of false matches: {count - 1}')\n",
    "        print()\n",
    "        multimatch += 1\n",
    "display(f'Single Matches: {len(matches)}')\n",
    "display(f'Multi Matches: {multimatch}')\n",
    "display(f'Non-Matches: {len(non_matches_the)}')\n",
    "display(f'Total news sources: {len(global_news)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_matches_the;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dict = {}\n",
    "for media, score in matches:\n",
    "    bias_dict.setdefault(media, score)\n",
    "global_news['bias'] = global_news['news'].map(bias_dict)\n",
    "global_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_news.bias.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_news.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of sentiment sources unranked for bias, by news type:')\n",
    "global_news.groupby(['financial_news'])['bias'].apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_news.groupby(['financial_news'])['bias'].apply(lambda x: x.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_news.to_csv(r'../../data/News_AI_Sentiments/news_media.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_media = global_news[global_news['bias'].notnull()]\n",
    "scored_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scored_media.bias);\n",
    "plt.title('Sentiment News-Source Bias-Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
